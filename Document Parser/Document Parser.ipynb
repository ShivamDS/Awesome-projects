{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Extracts and concatenates text from all pages of a PDF.\n",
    "\n",
    "    :param file_path: Path to the PDF file\n",
    "    :return: Full extracted text as a string\n",
    "    \"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "\n",
    "    for page_num, page in enumerate(doc, start=1):\n",
    "        page_text = page.get_text()\n",
    "        text += f\"\\n--- Page {page_num} ---\\n{page_text}\"\n",
    "    \n",
    "    doc.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af501bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "os.chdir(r\"C:\\Users\\shivam\\Documents\\GitHub\\Awesome-projects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # sample_path = r\"C:\\Users\\shivam\\Downloads\\oceans document.pdf\"\n",
    "    sample_path = \"oceans document.pdf\"\n",
    "    text = extract_text_from_pdf(sample_path)\n",
    "    print(text[:1000])  # Print the first 1000 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec886d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove extra whitespace and irrelevant formatting.\n",
    "\n",
    "    :param text: Raw extracted text\n",
    "    :return: Cleaned text\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\n+', '\\n', text)  # Collapse multiple newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)   # Collapse excessive whitespace\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3032937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = extract_text_from_pdf(sample_path)\n",
    "cleaned_text = clean_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0adb150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e65a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba87865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(\"API key found!\" if api_key else \"API key NOT found!\")\n",
    "\n",
    "# for testing\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=api_key\n",
    ")\n",
    "# openai.api_key = api_key\n",
    "\n",
    "def get_summary(text, model=\"gpt-4\"):\n",
    "    prompt = f\"\"\"\n",
    "    You are a business analyst assistant. Given the following business report, please provide an executive summary in 5 concise bullet points:\n",
    "\n",
    "    Report:\n",
    "    \\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.4,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b1ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5994c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_recommendations(text, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Generates 3-5 actionable next-step recommendations based on the report text.\n",
    "\n",
    "    :param text: Cleaned business report text\n",
    "    :param model: OpenAI model to use\n",
    "    :return: Recommendations as a string\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a senior business strategist.\n",
    "\n",
    "Based on the following business report, generate 3 to 5 **actionable next-step recommendations** that an executive team should consider. Recommendations should be strategic, concise, and realistic.\n",
    "\n",
    "Report:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b4737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ead4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text chunking\n",
    "\n",
    "# ðŸ“¦ Step 1: Chunk the Text\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def chunk_text_by_words(text, max_words=800, overlap=100):\n",
    "    \"\"\"\n",
    "    Split long text into overlapping chunks based on word count.\n",
    "\n",
    "    :param text: Cleaned input text\n",
    "    :param max_words: Max words per chunk\n",
    "    :param overlap: Number of overlapping words between chunks\n",
    "    :return: List of text chunks\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(start + max_words, len(words))\n",
    "        chunk = \" \".join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += max_words - overlap\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n",
    "# ðŸ’¡ Step 2: Summarize Each Chunk\n",
    "\n",
    "def summarize_chunks(chunks):\n",
    "    summaries = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Summarizing chunk {i + 1} of {len(chunks)}...\")\n",
    "        summary = get_summary(chunk)\n",
    "        summaries.append(f\"Chunk {i + 1} Summary:\\n{summary}\")\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "# ðŸ”— Step 3: Combine Summaries Into a Final Summary\n",
    "\n",
    "def aggregate_summaries(summaries):\n",
    "    combined = \"\\n\\n\".join(summaries)\n",
    "    \n",
    "    final_prompt = f\"\"\"\n",
    "You are a strategy consultant. Here are summaries of sections from a long business report.\n",
    "\n",
    "Please generate a final **executive summary** in 5 bullet points, incorporating the main insights across all sections.\n",
    "\n",
    "Sections:\n",
    "\\\"\\\"\\\"{combined}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": final_prompt}],\n",
    "        temperature=0.5,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# full flow\n",
    "\n",
    "text = extract_text_from_pdf(\"your_report.pdf\")\n",
    "cleaned_text = clean_text(text)\n",
    "\n",
    "chunks = chunk_text(cleaned_text)\n",
    "summaries = summarize_chunks(chunks)\n",
    "final_summary = aggregate_summaries(summaries)\n",
    "\n",
    "print(\"\\nðŸ“‹ Final Executive Summary:\\n\", final_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a6aac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba87b151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e4961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarization_pipeline.py\n",
    "\n",
    "import openai\n",
    "\n",
    "def get_summary(text, model=\"gpt-4\"):\n",
    "    prompt = f\"\"\"\n",
    "You are a business analyst assistant. Summarize the following section of a business report in 5 concise bullet points:\n",
    "\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.4,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def summarize_chunks(chunks):\n",
    "    summaries = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"ðŸ”¹ Summarizing chunk {i + 1}/{len(chunks)}\")\n",
    "        summary = get_summary(chunk)\n",
    "        summaries.append(summary)\n",
    "\n",
    "    return summaries\n",
    "\n",
    "\n",
    "def aggregate_summaries(summaries):\n",
    "    combined = \"\\n\\n\".join(summaries)\n",
    "    prompt = f\"\"\"\n",
    "You are a senior strategy consultant. Given the summaries of different sections of a business report below, generate a final executive summary in 5 key bullet points.\n",
    "\n",
    "Section Summaries:\n",
    "\\\"\\\"\\\"{combined}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.4,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "\n",
    "# âœ… Step 3: Use It in Your Notebook or Script\n",
    "\n",
    "from summarization_pipeline import (\n",
    "    chunk_text_by_words,\n",
    "    summarize_chunks,\n",
    "    aggregate_summaries,\n",
    ")\n",
    "from parser import extract_text_from_pdf, clean_text\n",
    "\n",
    "# Load and clean\n",
    "text = extract_text_from_pdf(\"report.pdf\")\n",
    "cleaned_text = clean_text(text)\n",
    "\n",
    "# Chunk and summarize\n",
    "chunks = chunk_text_by_words(cleaned_text, max_words=800, overlap=100)\n",
    "chunk_summaries = summarize_chunks(chunks)\n",
    "\n",
    "# Aggregate into final summary\n",
    "final_summary = aggregate_summaries(chunk_summaries)\n",
    "\n",
    "print(\"\\nðŸ“‹ Final Executive Summary:\\n\", final_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa1c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa33168",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"Hello, Streamlit!\")\n",
    "st.write(\"This is your first Streamlit app.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b3ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecc138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e825d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a1ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8f35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20105ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5fa198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115cbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cbd16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05db63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37478713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ddede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece7fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb5e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b7c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c96075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc4f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c87185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c84ee06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc3c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f31b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1e461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b785f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588193bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db21841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17621410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd3963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac682491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5310903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 pymupdf",
   "language": "python",
   "name": "pymupdf-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
